{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["Csy585je8sNB"],"authorship_tag":"ABX9TyNO1TlAVq5e0JI7fr2Dr4b7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# operazioni preliminari"],"metadata":{"id":"9FqLgbaT8zGA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8lKLZVrtnTfP"},"outputs":[],"source":["import os\n","import numpy as np\n","import os\n","from PIL import Image, ImageDraw\n","\n","from torch.utils.data import DataLoader\n","\n","import torch, torchvision\n","import torchvision.transforms as T\n","import pycocotools.coco as coco\n","from pycocotools.coco import COCO\n","import skimage.io as io\n","import matplotlib.pyplot as plt\n","import pylab\n","\n","!pip install wget"]},{"cell_type":"code","source":["print(torch.__version__, torch.cuda.is_available())\n","torch.set_grad_enabled(False);"],"metadata":{"id":"JUDAZLjmnX3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.transforms.transforms import Grayscale\n","# standard PyTorch mean-std input image normalization\n","transform = T.Compose([\n","    T.Resize(800),\n","    T.ToTensor(),\n","    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","# for output bounding box post-processing\n","def box_cxcywh_to_xyxy(x):\n","    x_c, y_c, w, h = x.unbind(1)\n","    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n","         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n","    return torch.stack(b, dim=1)\n","\n","def rescale_bboxes(out_bbox, size):\n","    img_w, img_h = size\n","    b = box_cxcywh_to_xyxy(out_bbox)\n","    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n","    return b"],"metadata":{"id":"AMbpeCc6nYNe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#clone woctezuma detr\n","%cd /content/\n","\n","!rm -rf detr\n","!git clone https://github.com/woctezuma/detr.git\n","\n","%cd detr/\n","\n","!git checkout finetune"],"metadata":{"id":"V-pvw8vFnYK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#carica pesi pre-addestrati\n","# Get pretrained weights\n","checkpoint = torch.hub.load_state_dict_from_url(\n","            url='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth',\n","            map_location='cpu',\n","            check_hash=True)\n","\n","# Remove class weights\n","del checkpoint[\"model\"][\"class_embed.weight\"]\n","del checkpoint[\"model\"][\"class_embed.bias\"]\n","\n","# Save\n","torch.save(checkpoint,\n","           'detr-r50_no-class-head.pth')"],"metadata":{"id":"_cImJ_CgnjiY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# operazioni su dataset per fine-tuning"],"metadata":{"id":"Csy585je8sNB"}},{"cell_type":"code","source":["path_ds = '/content/path_to_dataset'"],"metadata":{"id":"CkYrtsLTnjcw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_annotation_train = os.path.join(path_ds,'annotations/custom_train.json')"],"metadata":{"id":"dNeB4Tx_njaj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["controllo su dataset"],"metadata":{"id":"bXPyuFXRn8Nd"}},{"cell_type":"code","source":["# initialize COCO api for instance annotations\n","coco=COCO(path_annotation_train)"],"metadata":{"id":"Sdl2-Z5MnjWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# display COCO categories and supercategories\n","cats = coco.loadCats(coco.getCatIds())\n","\n","nms=[cat['name'] for cat in cats]\n","print('Categories: {}'.format(nms))\n","\n","nms = set([cat['supercategory'] for cat in cats])\n","print('Super-categories: {}'.format(nms))"],"metadata":{"id":"9jA7Hzk7nYIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load and display image\n","catIds = coco.getCatIds(catNms=['nome_categoria_da_ispezionare']);\n","imgIds = coco.getImgIds(catIds=catIds );"],"metadata":{"id":"aHPZj1S2oFwt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pylab.rcParams['figure.figsize'] = (8.0, 8.0)"],"metadata":{"id":"vNZh6wxwoGRN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_id = imgIds[np.random.randint(0,len(imgIds))]\n","print('Image nÂ°{}'.format(img_id))\n","\n","img = coco.loadImgs(img_id)[0]\n","\n","img_name = '%s/%s/%s'%(path_detr, '/train2017', img['file_name'])\n","print('Image name: {}'.format(img_name))\n","\n","I = io.imread(img_name)\n","plt.figure()\n","plt.imshow(I)"],"metadata":{"id":"Vhon8-7goHlk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds)\n","anns = coco.loadAnns(annIds)"],"metadata":{"id":"ekKvxYteoULF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load and display instance annotations\n","plt.imshow(I)\n","coco.showAnns(anns, draw_bbox=True)"],"metadata":{"id":"n1Xo9D5loUIs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# fine-tuning"],"metadata":{"id":"nvhz86prGEgx"}},{"cell_type":"code","source":["num_classes = numero_di_categorie\n","\n","CLASSES = finetuned_classes = [\n","      'N/A',\n","      'categoria_i-esima',\n","]"],"metadata":{"id":"jsDTAniwoUGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#training loop\n","!python main.py \\\n","  --dataset_file \"custom\" \\\n","  --coco_path \"/content/path_to_coco_ds\" \\\n","  --output_dir \"/content/output_directory\" \\\n","  --resume \"detr-r50_no-class-head.pth\" \\\n","  --num_classes $num_classes \\\n","  --epochs 10"],"metadata":{"id":"U4DWY0yBovF5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/path_to_model/.pth')"],"metadata":{"id":"JLFbq5jmqzMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load fine tuned model\n","model = torch.hub.load('facebookresearch/detr',\n","                       'detr_resnet50',\n","                       pretrained=False,\n","                       num_classes=num_classes)\n","\n","checkpoint = torch.load('/content/drive/MyDrive/.../checkpoint.pth',\n","                        map_location='cpu')\n","\n","model.load_state_dict(checkpoint['model'],\n","                      strict=False)\n","\n","model.eval();"],"metadata":{"id":"SPq4aGcspBmw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# inferenza con modello fine tuned"],"metadata":{"id":"86ZS3yPVMsz_"}},{"cell_type":"code","source":["# colors for visualization\n","COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n","          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"],"metadata":{"id":"jRtFeHzCpSeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_finetuned_results(pil_img, prob=None, boxes=None):\n","    plt.figure(figsize=(16,10))\n","    plt.imshow(pil_img)\n","    ax = plt.gca()\n","    colors = COLORS * 100\n","    if prob is not None and boxes is not None:\n","      for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n","          ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n","                                    fill=False, color=c, linewidth=3))\n","          cl = p.argmax()\n","          text = f'{finetuned_classes[cl]}: {p[cl]:0.2f}'\n","          ax.text(xmin+5, ymin-15, text, fontsize=15,\n","                  bbox=dict(facecolor='yellow', alpha=0.5))\n","    plt.axis('off')\n","    plt.savefig('/content/inferenza1.jpg',transparent = True, bbox_inches = 'tight', pad_inches = 0)"],"metadata":{"id":"Y2oVswb-pSbt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filter_bboxes_from_outputs(outputs,\n","                               threshold=0.7):\n","  \n","  # keep only predictions with confidence above threshold\n","  probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n","  keep = probas.max(-1).values > threshold\n","\n","  probas_to_keep = probas[keep]\n","\n","  # convert boxes from [0; 1] to image scales\n","  bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\n","  \n","  return probas_to_keep, bboxes_scaled"],"metadata":{"id":"SPzG7W51pSZH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def inference_single(my_image, my_model):\n","  # mean-std normalize the input image (batch-size: 1)\n","  img = transform(my_image).unsqueeze(0)\n","\n","  # propagate through the model\n","  outputs = my_model(img)\n","\n","  for threshold in [0.9, 0.7]:\n","    probas_to_keep, bboxes_scaled = filter_bboxes_from_outputs(outputs,\n","                                                              threshold=threshold)\n","\n","    plot_finetuned_results(my_image,\n","                           probas_to_keep, \n","                           bboxes_scaled)\n"],"metadata":{"id":"LDg8ZrtVpCJT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#inferenza su immagine singola\n","\n","img_name = '/content/path_to_image/.jpg'\n","im = Image.open(img_name)\n","im = im.convert('RGB')\n","inference_single((im), model)"],"metadata":{"id":"qG-z2XhRzUpU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#inferenza su cartella immagini\n","import glob\n","\n","for filename in glob.glob('/content/drive/MyDrive/.../*.jpg'): \n","    nome = (os.path.basename(filename))\n","    im=Image.open(filename)\n","\n","    img = transform(im).unsqueeze(0)\n","\n","    # propagate through the model\n","    outputs = model(img)\n","\n","    # keep only predictions with 0.7+ confidence\n","    probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n","    keep = probas.max(-1).values > 0.9\n","\n","    # convert boxes from [0; 1] to image scales\n","    bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\n","\n","    plt.figure(figsize=(16,10))\n","    plt.imshow(im)\n","    ax = plt.gca()\n","    colors = COLORS * 100\n","    for p, (xmin, ymin, xmax, ymax), c in zip(probas[keep], bboxes_scaled.tolist(), colors):\n","          ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n","                                   fill=False, color=c, linewidth=3))\n","          cl = p.argmax()\n","          text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n","          ax.text(xmin, ymin, text, fontsize=15,\n","                bbox=dict(facecolor='yellow', alpha=0.5))\n","    plt.axis('off')\n","    path = os.path.join(\"/content/\",nome)\n","    plt.savefig(path,transparent = True, bbox_inches = 'tight', pad_inches = 0)\n","    plt.close()\n","    print(nome)"],"metadata":{"id":"dwWfsIAi1Q_m"},"execution_count":null,"outputs":[]}]}
